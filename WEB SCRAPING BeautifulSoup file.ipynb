{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171ae031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f440281",
   "metadata": {},
   "source": [
    "# 1)\tWrite a python program to display all the header tags from wikipedia.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb04194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_header_tags(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the webpage\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all header tags (h1, h2, h3, etc.)\n",
    "        header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        \n",
    "        # Extract text from header tags and print\n",
    "        for tag in header_tags:\n",
    "            print(tag.text.strip())\n",
    "    else:\n",
    "        print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "\n",
    "# URL of the webpage to scrape (Wikipedia in this case)\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "\n",
    "# Call the function to get and display all header tags\n",
    "get_header_tags(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc0a80",
   "metadata": {},
   "source": [
    "# 2)\tWrite a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972c8a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the webpage. Status code: 403\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_100_movies():\n",
    "    # URL of the IMDB page with top 100 movies\n",
    "    url = \"https://www.imdb.com/chart/top\"\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the webpage\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all movie entries\n",
    "        movie_entries = soup.find_all('td', class_='titleColumn')\n",
    "        \n",
    "        # Initialize lists to store movie data\n",
    "        names = []\n",
    "        ratings = []\n",
    "        years = []\n",
    "        \n",
    "        # Extract data for each movie\n",
    "        for movie in movie_entries[:100]:  # Only top 100 movies\n",
    "            name = movie.a.text\n",
    "            rating = movie.find_next_sibling('td', class_='ratingColumn').strong.text\n",
    "            year = movie.span.text.strip('()')\n",
    "            \n",
    "            # Append data to lists\n",
    "            names.append(name)\n",
    "            ratings.append(rating)\n",
    "            years.append(year)\n",
    "        \n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({'Name': names, 'Rating': ratings, 'Year': years})\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Call the function to get the top 100 movies data\n",
    "top_100_movies_df = get_top_100_movies()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(top_100_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5bbaf6",
   "metadata": {},
   "source": [
    "# 3)\tWrite a python program to scrape mentioned details from dineout.co.in : i) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d5a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_dineout_details():\n",
    "    # URL of the dineout.co.in page with restaurant details\n",
    "    url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the webpage\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all restaurant entries\n",
    "        restaurant_entries = soup.find_all('div', class_='listing-details-right')\n",
    "\n",
    "        # Initialize lists to store restaurant details\n",
    "        restaurant_details = []\n",
    "\n",
    "        # Extract data for each restaurant\n",
    "        for restaurant in restaurant_entries:\n",
    "            # Restaurant name\n",
    "            name = restaurant.h3.text.strip()\n",
    "\n",
    "            # Cuisine\n",
    "            cuisine = restaurant.find('span', class_='double-line-ellipsis').text.strip()\n",
    "\n",
    "            # Location\n",
    "            location = restaurant.find('span', class_='restnt-loc').text.strip()\n",
    "\n",
    "            # Ratings\n",
    "            rating = restaurant.find('div', class_='rating-score').text.strip()\n",
    "\n",
    "            # Image URL\n",
    "            image_url = restaurant.img['data-src']\n",
    "\n",
    "            # Store details in a dictionary\n",
    "            details = {\n",
    "                'Restaurant Name': name,\n",
    "                'Cuisine': cuisine,\n",
    "                'Location': location,\n",
    "                'Ratings': rating,\n",
    "                'Image URL': image_url}\n",
    "\n",
    "            # Append details to the list\n",
    "            restaurant_details.append(details)\n",
    "\n",
    "        return restaurant_details\n",
    "    else:\n",
    "        print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Call the function to scrape dineout details\n",
    "dineout_details = scrape_dineout_details()\n",
    "\n",
    "# Print the details\n",
    "for details in dineout_details:\n",
    "    print(\"Restaurant Name:\", details['Restaurant Name'])\n",
    "    print(\"Cuisine:\", details['Cuisine'])\n",
    "    print(\"Location:\", details['Location'])\n",
    "    print(\"Ratings:\", details['Ratings'])\n",
    "    print(\"Image URL:\", details['Image URL'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d829ea3",
   "metadata": {},
   "source": [
    "# 4)\tWrite s python program to display list of respected former finance minister of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21d19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the webpage. Status code: 404\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_former_finance_ministers():\n",
    "    # URL of the page with former presidents' details\n",
    "    url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the webpage\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the table containing former presidents' details\n",
    "        table = soup.find('table', class_='tablepress tablepress-id-42')\n",
    "\n",
    "        # Initialize lists to store former finance ministers' details\n",
    "        names = []\n",
    "        terms_of_office = []\n",
    "\n",
    "        # Extract data for each row in the table (skipping the header row)\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "        for row in rows:\n",
    "            # Extract data from columns\n",
    "            columns = row.find_all('td')\n",
    "            name = columns[0].text.strip()\n",
    "            term_of_office = columns[1].text.strip()\n",
    "\n",
    "            # Append data to lists\n",
    "            names.append(name)\n",
    "            terms_of_office.append(term_of_office)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({'Name': names, 'Term of Office': terms_of_office})\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Call the function to scrape former finance ministers' details\n",
    "former_finance_ministers_df = scrape_former_finance_ministers()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(former_finance_ministers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec8928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
